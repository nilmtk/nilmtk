{
 "metadata": {
  "name": "",
  "signature": "sha256:7b279dfd3fc21a4a5b95b317e4ab032d1cc1ee46b14b5681b838c4c89b6fd1d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Processing pipeline, preprocessing and more stats"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At the core of NILMTK v0.2 is the concept of an 'out-of-core' processing pipeline.  What does that mean?  'out-of-core' refers to the ability to handle datasets which are too large to fit into system memory.  NILMTK achieves this by setting up a processing pipeline which handle a chunk of data at a time. We load small chunks from disk and pull these chunks through a processing pipeline.  Each pipeline is made up of `Nodes`.  These can either be stats nodes or preprocessing nodes.  Under the hood, a pipeline is implemented as a chain of Python `generators`.  Stats nodes live in `nilmtk.stats` and preprocessing nodes in `nilmtk.preprocessing`.  Most stats are wrapped by helper functions in `ElecMeter` and `MeterGroup` so you only have to dive in an play directly with Nodes and the pipeline if you want to assemble your own stats and preprocessing functions.\n",
      "\n",
      "Having a pipeline which can handle small chunks not only allows us to load arbitrarily large datasets.  It also allows us to calculate stats on arbitrary sized chunks of data (e.g. energy per day, or appliance usage per week etc).  To facilitate this, Stats nodes (e.g. for calculating total energy or for finding missing samples) store their results in a separate `Results` object.  For example, the `TotalEnergy` stats node stores its results in a `TotalEnergyResults` object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilmtk import DataSet\n",
      "\n",
      "redd = DataSet('/data/REDD/redd.h5')\n",
      "elec = redd.buildings[1].elec\n",
      "fridge_meter = elec['fridge']\n",
      "\n",
      "total_fridge_energy = fridge_meter.total_energy(full_results=True)\n",
      "type(total_fridge_energy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "nilmtk.stats.totalenergyresults.TotalEnergyResults"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_fridge_energy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "                              active                        end\n",
        "2011-04-18 09:22:13-04:00  44.750925  2011-05-24 15:56:34-04:00"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why store results in their own objects?  Because these objects need to know how to combine results from multiple chunks.\n",
      "\n",
      "So, for example, let us get the total energy per day:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilmtk.timeframe import timeframes_from_periodindex\n",
      "import pandas as pd\n",
      "\n",
      "# First find the total time span for the fridge data:\n",
      "tf = fridge_meter.get_timeframe()\n",
      "tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "TimeFrame(start='2011-04-18 09:22:13-04:00', end='2011-05-24 15:56:34-04:00', empty=False)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now make a PeriodIndex of daily periods:\n",
      "period_index = pd.period_range(start=tf.start, periods=5, freq='D')\n",
      "list(period_index) # just converting to a list for pretty printing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "[Period('2011-04-18', 'D'),\n",
        " Period('2011-04-19', 'D'),\n",
        " Period('2011-04-20', 'D'),\n",
        " Period('2011-04-21', 'D'),\n",
        " Period('2011-04-22', 'D')]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can get the energy per day:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "energy_per_day = fridge_meter.total_energy(sections=period_index, full_results=True)\n",
      "energy_per_day"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                             active                        end\n",
        "2011-04-18 09:22:13-04:00  0.678742  2011-04-18 19:59:59-04:00\n",
        "2011-04-18 20:00:03-04:00  1.153877  2011-04-19 18:45:09-04:00\n",
        "2011-04-19 20:20:05-04:00  1.244343  2011-04-20 19:59:59-04:00\n",
        "2011-04-20 20:00:03-04:00  1.003537  2011-04-21 19:59:56-04:00\n",
        "2011-04-21 20:00:00-04:00  1.219889  2011-04-22 19:59:58-04:00"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And there we have it: the energy use per day.  The days start at 8pm because REDD is UTC-4:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "redd.metadata['timezone']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'US/Eastern'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we can combine all the energy results from each day:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "energy_per_day.combined()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "active    5.300387\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To make the code as re-usable as possible, each stats module has a `get_<stat>` function which takes a vanilla DataFrame."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load a restricted window of data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilmtk import TimeFrame\n",
      "fridge_meter.store.window = TimeFrame(\"2011-04-20  20:00:00-04:00\", \"2011-04-25  20:00:00-04:00\")\n",
      "fridge_meter.get_timeframe()\n",
      "# all subsequent processing will only consider the defined window"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "TimeFrame(start='2011-04-20 20:00:00-04:00', end='2011-04-25 20:00:00-04:00', empty=False)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To reset the timeframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fridge_meter.store.window.clear()\n",
      "fridge_meter.get_timeframe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "TimeFrame(start='2011-04-18 09:22:13-04:00', end='2011-05-24 15:56:34-04:00', empty=False)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The `Apply` preprocessing node"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have an `Apply` node which applies an arbitrary Pandas function to every chunk as it moves through the pipeline:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilmtk.preprocessing import Apply\n",
      "from nilmtk.stats import DropoutRate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fridge_meter.store.window = TimeFrame(\"2011-04-21  20:00:00-04:00\", \"2011-04-23  20:00:00-04:00\")\n",
      "good_sections = fridge_meter.good_sections()\n",
      "good_sections"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[TimeFrame(start='2011-04-21 20:00:00-04:00', end='2011-04-22 22:46:53-04:00', empty=False),\n",
        " TimeFrame(start='2011-04-22 22:48:31-04:00', end='2011-04-23 19:59:59-04:00', empty=False)]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Fill gaps in appliance data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# So, we're going to construct a new pipeline.\n",
      "# First we need to get a 'source node' from an ElecMeter or a MeterGroup:\n",
      "source_node = fridge_meter.get_source_node(sections=good_sections)\n",
      "\n",
      "# Then, just to see what's going on, we'll work out the dropout rate\n",
      "# before we've done any resampling.  We connect the source_node to the DropoutRate node:\n",
      "dropout_rate1 = DropoutRate(source_node)\n",
      "\n",
      "# The third node will be an Apply node.  We'll use Pandas' resample function:\n",
      "resample = Apply(func = lambda df: pd.DataFrame.resample(df, rule='3S', fill_method='ffill'), \n",
      "                 upstream=dropout_rate1)\n",
      "\n",
      "# Then we're calculate the dropout rate again.  This should be 0.0 because we've\n",
      "# resampled...\n",
      "dropout_rate2 = DropoutRate(resample)\n",
      "\n",
      "# At this point, no data has been loaded from disk yet.  We need to 'pull' data\n",
      "# through the pipeline by running 'run' on the last node in the pipeline:\n",
      "\n",
      "dropout_rate2.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The dropout rate before resampling:\n",
      "dropout_rate1.results.combined()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "0.22210446987463711"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The dropout rate after resampling:\n",
      "dropout_rate2.results.combined()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 23
    }
   ],
   "metadata": {}
  }
 ]
}
